import ollama 
import subprocess
import os
import csv
import time
from pathlib import Path
import argparse
import ast
# import mini_selector as mini

ollama_model = "llama3.1:8b"
ip_address ="10.129.246.225"
problem_description = f"Solve a ctf at the IP {ip_address}" 
start_message= [{'role': "system", 'content': f"You are a ctf solver and you are given a task to solve a ctf at the IP {ip_address} and you need to use the extract_code tool everytime. To reiterate you must use the tool call no matter what."}]
Timed_out = False
continual_messages = ''
challenge = "Unified"
session_name = "_ctf"
manual = False
# Command line arguments
parser = argparse.ArgumentParser(description="Example script with options")
parser.add_argument("-i", "--ip", dest="ip_address", help="IP address of the CTF")
parser.add_argument("-m", "--model", dest="ollama_model", help="Ollama model to use")
parser.add_argument("-d", "--description", dest="problem_description", help="Description of the problem")
parser.add_argument("-c", "--continual", dest="continual_messages", help="Continual messages")
parser.add_argument("-e", "--manual", help="Puts the code into manual mode: enter to do next command", action="store_true")

args = parser.parse_args()

if args.ip_address:
    ip_address = args.ip_address
if args.manual:
    manual = True
if args.ollama_model:
    ollama_model = args.ollama_model

if args.problem_description:
    problem_description = args.problem_description

if args.continual_messages or continual_messages != '':
    with open(args.continual_messages, 'r') as f:
        read = f.read()
        start_message = ast.literal_eval(read)

# creates a unique log file stored in ctf logs
def createUniqueLog(filename, directory=f"/home/matt/Desktop/AACT/{ollama_model}/ctflogs"):
    counter = 1 
    while True:
        file = Path(directory) / f"{filename}_{counter}.csv"
        mess_file = Path(directory) / f"{filename}_{counter}_messages.txt"
        if not os.path.exists(file):
            with file.open('w', newline='') as f:
                info = ["command number", "command", "reasoning", "reasoning time", "output", "command time"]
                writer = csv.writer(f)
                writer.writerow(info)
                # f.write(f"This is instance log #{counter} of {filename}\n")
                # f.write("command number, command,reasoning, output ")
                print(f"[+] File create: {str(file)}")
            with mess_file.open('w', newline='') as f:
                f.write("this is suppose to hold the memory")
                print(f"[+] File create: {str(mess_file)}")

            return file,mess_file

        counter += 1

# call to run the AI including the tool call to extract_code
def tool_ollama(messages, prompt):
    """ Sends a prompt to Ollama and gets a response """
    #print(prompt)
    messages.append(
        {"role": "user", 
         "content": prompt,
        })
    #tool call basic format found on https://ollama.com/docs/api
    get_code = [{
                    'type': "function",
                    'function': {
                        'name': 'extract_code',
                        'description': 'provides the next command to run',
                        'parameters' : {
                            'type': 'object',
                            'properties': {
                                "code_type" : {
                                    "type": "string",
                                    "description": "The type of code that is getting extract"
                                },
                                "code" :{
                                    "type": "string",
                                    "description": "The code that is getting extract"
                                },
                                "why" : {
                                    "type": "string",
                                    "description": "The reason for the choosing that code"
                                }
                            },
                            'required': ['code_type', 'code']
                        }
                    }
                }]
    response = ollama.chat(model=ollama_model, 
                           messages=messages,
                           tools=get_code
                           )
    print(response)
    # return response['message']['tool_calls']
    return (response['message']['tool_calls'], messages)


def wait_response(sig_name, mess):
    global Timed_out
    try:
        subprocess.run(f"tmux wait-for {sig_name}", shell=True,timeout=30)
        Timed_out = False

    except subprocess.TimeoutExpired:
        # output = subprocess.run(f"tmux capture-pane -p -t {session_name}", shell=True, capture_output=True, text=True).stdout
        # output = output[output.rfind(sig_name) + len(sig_name):].strip()
        # status = mini.selector(mess, output)
        # print(f"[+] Is the command Finished: {status[0]}")
        # print(f"[+] Expected next ti: {status}")
        Timed_out = True
        # if status[0]:
        #     return True
        # return wait_response(sig_name, mess)
        print("[+] Command took too long to execute. Moving on to the next command.")
        

def run_terminal():
    global Timed_out
    global session_name
    """ Opens a persistent tmux session and executes commands inside it """
    
    # Start a tmux session
    session_name = f"_ctf"
    subprocess.run(f"tmux new-session -d -s {session_name}", shell=True)
    print("[+] tmux session started. Running commands inside it.")

    #create log file 
    file,mess_file = createUniqueLog(challenge)
    #problem_description = "Solve a ctf at the IP 10.129.91.189"
    start = time.time()
    if continual_messages == '':
        full_command, messages = tool_ollama(start_message, f"{problem_description} Suggest the first command to solve the ctf .")
    else:
        full_command, messages = tool_ollama(start_message, f"What is the next step to solve the ctf?")
    ollama_time = time.time() - start
    sig_name = "à¸ž"
    

    # counter for logging which command it is
    counter = 1
    while True:

        ########################### Isolating variabes from llama ###############################
        broken_up = full_command[0]['function']['arguments']
        next_command = broken_up['code']
        why = ''
        if broken_up['why']:
            why = broken_up['why']
        ##########################################################################################

        print(f"[+] Ollama suggests: {next_command}")
        # if (full_command[0]['function']['arguments']['why']):
        #     print(full_command[0]['function']['arguments']['why'])
        # Run command inside tmux session
        start = time.time()
        if Timed_out:
            subprocess.run(f"tmux send-keys -t {session_name} \"{next_command}\" C-m", shell=True)
        else:
            subprocess.run(f"tmux send-keys -t {session_name} '{next_command}; tmux wait-for -S {sig_name}' C-m", shell=True)
        if manual:
            print(f"[+] Press enter to continue: 'y' to send with signal or 'n' to send without signal")
            ti = input()
            if ti == 'n':
                Timed_out = True
            else:
                Timed_out = False
        else:
            Timed_out = wait_response(sig_name, next_command)
        command_time = time.time() - start
        # Simulate waiting for command execution
        output = subprocess.run(f"tmux capture-pane -p -t {session_name}", shell=True, capture_output=True, text=True).stdout
        output = output[output.rfind(sig_name) + len(sig_name):].strip()

        #################                   creating continous ai chat log                 #################
        messages.append({'role': "assistant", 'content': f"Ollama suggested {next_command} because {why}"})
        messages.append({'role': "system", 'content': f"Executed {next_command} : Results: {output}"})
        ####################################################################################################

        ############################# Logging the command and output ############################
        with file.open('a',newline='') as f:
            instance = [counter , next_command , why , ollama_time, output[output.rfind(sig_name)+len(sig_name):].strip(), command_time]
            writer = csv.writer(f,quoting=csv.QUOTE_ALL)
            writer.writerow(instance)
            counter += 1

        with mess_file.open('w',newline='') as f:
            f.write(str(messages))
            f.write("\n")
        ##########################################################################################

        print(f"[+] Command Output:\n{output}")

        # if "exit" in next_command.lower():
        #     print("[+] Ollama decided to stop.")
        #     break
        start = time.time()
        full_command, messages = tool_ollama(messages, f"What is the next step to solve the ctf?")
        ollama_time = time.time() - start
        #full_command, messages = tool_ollama(messages, f"The last command was: {next_command} The output was: {output}\nWhat is the next command to solve the ctf at this ip {ip_address}?")

    # Close tmux session
    subprocess.run(f"tmux kill-session -t {session_name}", shell=True)
    print("[+] tmux session closed.")



if __name__ == "__main__":

    run_terminal()
